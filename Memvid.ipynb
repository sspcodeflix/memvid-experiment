{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a2839af062aa4c66a3f0846133b6d8db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c66bf6f2f1944b0bb7cd6172921c37f3",
              "IPY_MODEL_3528347b0aac4f049b52a2cba2289dbd",
              "IPY_MODEL_49f15c526d4f44bb9fffe77e2fe040b8"
            ],
            "layout": "IPY_MODEL_4434cfa45c534bc590506e5f05e79529"
          }
        },
        "c66bf6f2f1944b0bb7cd6172921c37f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3910dc874dc94412949f98621a662cec",
            "placeholder": "​",
            "style": "IPY_MODEL_8bc3563760974f09a081cacad29ded44",
            "value": "Batches: 100%"
          }
        },
        "3528347b0aac4f049b52a2cba2289dbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e68d5a69a0324f60b298df486f803032",
            "max": 6,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a93ffef9948f4353a5f24c47b8cbe3f1",
            "value": 6
          }
        },
        "49f15c526d4f44bb9fffe77e2fe040b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3081555067fe48408af5c26739a63e43",
            "placeholder": "​",
            "style": "IPY_MODEL_0d02f7c4ad3a47f09aa017c1d73993d5",
            "value": " 6/6 [00:14&lt;00:00,  2.48s/it]"
          }
        },
        "4434cfa45c534bc590506e5f05e79529": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3910dc874dc94412949f98621a662cec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8bc3563760974f09a081cacad29ded44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e68d5a69a0324f60b298df486f803032": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a93ffef9948f4353a5f24c47b8cbe3f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3081555067fe48408af5c26739a63e43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d02f7c4ad3a47f09aa017c1d73993d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DHoL3KLhOJtG"
      },
      "outputs": [],
      "source": [
        "!pip install -q memvid PyPDF2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PyPDF2 import PdfReader\n",
        "\n",
        "from memvid import MemvidEncoder, MemvidChat\n",
        "from google.colab import files, userdata\n"
      ],
      "metadata": {
        "id": "DN4UfCcOZhlW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()\n",
        "pdf_path = list(uploaded.keys())[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "0BAXr1_VP1TX",
        "outputId": "5e62790b-7b66-4552-90c2-9d2d9d1f0739"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-637c25d4-d9f5-432f-812b-786acba3f168\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-637c25d4-d9f5-432f-812b-786acba3f168\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving idfc-mitc.pdf to idfc-mitc.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text_from_pdf(pdf_path, password=None):\n",
        "    \"\"\"\n",
        "    Extracts text content from a PDF file, including support for password-protected (encrypted) PDFs.\n",
        "\n",
        "    This function reads a PDF file page by page, decrypts it if needed,\n",
        "    and extracts text from each page. Pages with no text (e.g., scanned images) are skipped.\n",
        "\n",
        "    Args:\n",
        "        pdf_path (str): Path to the input PDF file.\n",
        "        password (str, optional): Password to decrypt the PDF, if it's encrypted. Defaults to None.\n",
        "\n",
        "    Returns:\n",
        "        List[str]: A list of extracted text strings, one per successfully processed page.\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If the PDF is encrypted and no password is provided or if decryption fails.\n",
        "    \"\"\"\n",
        "    reader = PdfReader(pdf_path)\n",
        "\n",
        "    # Handle encrypted PDFs\n",
        "    if reader.is_encrypted:\n",
        "        if password is None:\n",
        "            raise ValueError(\"PDF is encrypted. Please provide the password.\")\n",
        "        try:\n",
        "            reader.decrypt(password)\n",
        "        except Exception as e:\n",
        "            raise ValueError(\"Failed to decrypt PDF. Is the password correct?\") from e\n",
        "\n",
        "    # Extract text from each page\n",
        "    text_chunks = []\n",
        "    for page_num, page in enumerate(reader.pages):\n",
        "        text = page.extract_text()\n",
        "        if text:\n",
        "            text_chunks.append(text)\n",
        "        else:\n",
        "            print(f\"No text extracted from page {page_num + 1} (may be scanned or image-based)\")\n",
        "    return text_chunks"
      ],
      "metadata": {
        "id": "XFLoQnluULm0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PyPDF2 import PdfReader\n",
        "from memvid import MemvidEncoder\n",
        "\n",
        "def split_text_into_chunks(text, max_length=400):\n",
        "    \"\"\"\n",
        "    Splits a long string of text into smaller chunks of fixed maximum length.\n",
        "\n",
        "    Args:\n",
        "        text (str): The input text to split.\n",
        "        max_length (int, optional): Maximum number of characters per chunk. Defaults to 400.\n",
        "\n",
        "    Returns:\n",
        "        List[str]: A list of text chunks.\n",
        "    \"\"\"\n",
        "    return [text[i:i + max_length] for i in range(0, len(text), max_length)]\n",
        "\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    \"\"\"\n",
        "    Extracts text content from each page of a PDF file.\n",
        "\n",
        "    Args:\n",
        "        pdf_path (str): Path to the input PDF file.\n",
        "\n",
        "    Returns:\n",
        "        List[str]: A list of text content per page. Empty pages are skipped.\n",
        "    \"\"\"\n",
        "    reader = PdfReader(pdf_path)\n",
        "    text_chunks = []\n",
        "    for page_num, page in enumerate(reader.pages):\n",
        "        text = page.extract_text()\n",
        "        if text:\n",
        "            text_chunks.append(text)\n",
        "        else:\n",
        "            print(f\"⚠️ No text found on page {page_num + 1}. It may be scanned or image-based.\")\n",
        "    return text_chunks\n",
        "\n",
        "\n",
        "def build_memvid_from_pdf(pdf_path, video_file=\"/content/memory.mp4\", index_file=\"/content/memory_index.json\", password=None):\n",
        "    \"\"\"\n",
        "    Converts a PDF document into a searchable AI memory stored in a video file using Memvid.\n",
        "\n",
        "    This function performs the following steps:\n",
        "        1. Extracts text from the PDF.\n",
        "        2. Splits text into smaller chunks.\n",
        "        3. Encodes chunks into a video using MemvidEncoder.\n",
        "        4. Saves the video (.mp4) and index (.json) for later retrieval.\n",
        "\n",
        "    Args:\n",
        "        pdf_path (str): Path to the input PDF file.\n",
        "        video_file (str, optional): Output path for the generated MP4 memory file. Defaults to '/content/memory.mp4'.\n",
        "        index_file (str, optional): Output path for the memory index JSON file. Defaults to '/content/memory_index.json'.\n",
        "        password (str, optional): Password to decrypt the PDF if it is encrypted. Currently unused.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    raw_chunks = extract_text_from_pdf(pdf_path)\n",
        "\n",
        "    # Further split page-wise text into smaller chunks for QR encoding compatibility\n",
        "    chunks = []\n",
        "    for page_text in raw_chunks:\n",
        "        chunks.extend(split_text_into_chunks(page_text, max_length=400))  # Keep chunks small for video encoding\n",
        "\n",
        "    print(f\"Total chunks prepared: {len(chunks)}\")\n",
        "\n",
        "    # Initialize encoder and build the memory video\n",
        "    encoder = MemvidEncoder()\n",
        "    encoder.add_chunks(chunks)\n",
        "    encoder.build_video(video_file, index_file)\n",
        "\n",
        "    print(f\"Memory video saved as: {video_file}\")\n",
        "    print(f\"Index file saved as: {index_file}\")\n"
      ],
      "metadata": {
        "id": "cg_QuWrWOtjv"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chat_with_memvid(\n",
        "        video_file=\"/content/memory.mp4\",\n",
        "        index_file=\"/content/memory_index.json\"):\n",
        "    \"\"\"\n",
        "    Launches an interactive chat session with a Memvid video memory using an OpenAI-powered LLM.\n",
        "\n",
        "    This function initializes a MemvidChat instance using a pre-built memory (MP4 + index),\n",
        "    starts the session, and enters a REPL-style loop where the user can ask questions\n",
        "    about the contents stored in the video memory.\n",
        "\n",
        "    Args:\n",
        "        video_file (str): Path to the memory video (.mp4) file. Defaults to '/content/memory.mp4'.\n",
        "        index_file (str): Path to the memory index (.json) file. Defaults to '/content/memory_index.json'.\n",
        "\n",
        "    Requirements:\n",
        "        - The environment variable or `userdata` dictionary must contain a valid 'OPENAI_API_KEY'.\n",
        "        - The video and index files must have been previously created using MemvidEncoder.\n",
        "        - `MemvidChat` should be imported from the memvid library.\n",
        "\n",
        "    Behavior:\n",
        "        - Continues until the user types 'exit' or 'quit'.\n",
        "        - Uses OpenAI's GPT-3.5-turbo for LLM responses.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    chat = MemvidChat(\n",
        "        video_file,\n",
        "        index_file,\n",
        "        llm_provider=\"openai\",\n",
        "        llm_model=\"gpt-3.5-turbo\",\n",
        "        llm_api_key=userdata.get('OPENAI_API_KEY')  # Assumes key is stored securely in userdata\n",
        "    )\n",
        "\n",
        "    chat.start_session()  # Load memory into searchable format\n",
        "\n",
        "    # Interactive question-answer loop\n",
        "    while True:\n",
        "        query = input(\"Ask something (or type 'exit'): \")\n",
        "        if query.lower() in [\"exit\", \"quit\"]:\n",
        "            break\n",
        "        response = chat.chat(query)\n",
        "        print(\"Bot:\", response)"
      ],
      "metadata": {
        "id": "Oj4qzKj3Vcph"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "build_memvid_from_pdf(pdf_path)\n",
        "chat_with_memvid()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468,
          "referenced_widgets": [
            "a2839af062aa4c66a3f0846133b6d8db",
            "c66bf6f2f1944b0bb7cd6172921c37f3",
            "3528347b0aac4f049b52a2cba2289dbd",
            "49f15c526d4f44bb9fffe77e2fe040b8",
            "4434cfa45c534bc590506e5f05e79529",
            "3910dc874dc94412949f98621a662cec",
            "8bc3563760974f09a081cacad29ded44",
            "e68d5a69a0324f60b298df486f803032",
            "a93ffef9948f4353a5f24c47b8cbe3f1",
            "3081555067fe48408af5c26739a63e43",
            "0d02f7c4ad3a47f09aa017c1d73993d5"
          ]
        },
        "id": "p-tC_1KmaHrZ",
        "outputId": "f7b737db-a14d-4bd7-df6e-01cd3b5af517"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⚠️ No text found on page 26. It may be scanned or image-based.\n",
            "Total chunks prepared: 189\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Generating QR frames: 100%|██████████| 189/189 [00:45<00:00,  4.17it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/memvid/encoder.py:476: UserWarning: h265 encoding failed: Invalid suffix 'mkv'. Falling back to MP4V.\n",
            "  warnings.warn(f\"{codec} encoding failed: {e}. Falling back to MP4V.\", UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🐛 FRAMES: 189 files in /tmp/tmpmonnhcq0/frames\n",
            "🐛 FFMPEG: frames=/tmp/tmpmonnhcq0/frames → docker_mount=/tmp/tmpmonnhcq0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Writing video frames: 100%|██████████| 189/189 [00:00<00:00, 246.22it/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/6 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a2839af062aa4c66a3f0846133b6d8db"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Memory video saved as: /content/memory.mp4\n",
            "Index file saved as: /content/memory_index.json\n",
            "Using openai for responses.\n",
            "--------------------------------------------------\n",
            "Ask something (or type 'exit'): what is this document about ?\n",
            "Bot: The document mentioned in the contexts provided is about the Most Important Terms and Conditions (MITC) related to a card offered by IDFC FIRST Bank and its partner. It covers various aspects such as card usage guidelines, consequences of certain actions (like delay in payments or misuse of the card), necessary information sharing with co-branded partners, and grievance redressal procedures. It also includes details on rewards programs, portfolio statistical analysis, and compliance with relevant laws and regulations.\n",
            "Ask something (or type 'exit'): whats the best card for people with annual income less than 5lakhs\n",
            "Bot: Based on the provided contexts from the knowledge base, the best card for people with an annual income less than 5 lakhs could be the FIRST Millennium Credit Card as it has no capping on the benefits provided and is applicable to individuals with lower incomes. This card could be a favorable option for those looking for a credit card without specific income requirements or limitations on benefits. However, for more specific recommendations tailored to individual preferences and requirements, it is advisable to explore further details or consult with the respective bank's offerings.\n",
            "Ask something (or type 'exit'): exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Feature / Approach          | **Memvid (Video-as-DB)**        | **FAISS / Qdrant**          | **Cloud RAG (LangChain, Pinecone)** | **Local RAG + Ollama / Llama.cpp**   |\n",
        "| --------------------------- | ------------------------------- | --------------------------- | ----------------------------------- | ------------------------------------ |\n",
        "| **Storage Format**          | `.mp4` + `.json`                | Vector index                | Cloud vector store                  | Local vector index                   |\n",
        "| **Database Needed**         | ❌ None                          | ✅ Yes (in-memory/on-disk)   | ✅ Yes (e.g., Pinecone, Weaviate)    | ✅ Yes (e.g., Chroma, FAISS)          |\n",
        "| **Internet Required**       | ❌ No                            | ❌ No                        | ✅ Yes                               | ❌ No                                 |\n",
        "| **LLM Integration**         | OpenAI, Claude, Gemini          | Pluggable                   | API-based (OpenAI, Cohere, etc.)    | Local models (Mistral, LLaMA2, etc.) |\n",
        "| **Offline Compatibility**   | ✅ Full                          | ✅ Full                      | ❌ No                                | ✅ Full                               |\n",
        "| **File Format Portability** | ✅ `.mp4` shareable              | ❌ Model-dependent           | ❌ Cloud-locked                      | ✅ Local disk                         |\n",
        "| **Setup Complexity**        | 🟢 Super simple                 | 🟡 Moderate                 | 🔴 High                             | 🟡 Moderate                          |\n",
        "| **Use Case Fit**            | Portable AI memory, quick demos | Production RAG, fast search | Scalable enterprise-grade RAG       | Privacy-first apps, dev workflows    |\n",
        "| **Scalability**             | 🚫 Limited by video encoding    | ✅ Highly scalable           | ✅ Cloud autoscale                   | 🟡 Scales with local resources       |\n",
        "| **Security & Privacy**      | ✅ Strong (local-only)           | ✅ Strong (local option)     | ❌ Data leaves system                | ✅ Strong (no external access)        |\n",
        "| **Ideal For**               | Students, demos, offline tools  | Internal RAG systems        | Customer-facing apps, chatbots      | Hackers, tinkerers, local assistants |\n"
      ],
      "metadata": {
        "id": "oae8UfHtgaii"
      }
    }
  ]
}